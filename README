---- AUTHOR ----
AUTHOR:      Vicente Adolfo Bolea Sanchez
EMAIL:       <vicente.bolea@gmail.com>.
             <vicente.bolea@unist.ac.kr>
INSTITUTION: UNIST at DICL laboratory.

---- PRELIMINARIES ----
This is an experiment for indexing data in a distribute system.
The model of this experiment is based on hybrid peer-to-peer model, 
with an central scheduler and a set of nodes.

These nodes are interconnected each others and connected with
the scheduler.

The porpose of this experiment is to run differents algorithms
in a distributed system using differents technics.


---- REQUIREMENTS ----
*The source code is coded in c++99 for linux.

*You will need in each node and enough big file of garbage to
 test the LRU cache throughput. the size of this file should be
	as big as the domain of the data set.

*An bash terminal.


---- USAGE ----
To run the experiment you need to setup some variable in
Makefile.vars such as: number of servers, port, host, etc...
Then compile and execute the launcher script located in the
binary folder.
Here are the script's flags:

$ launcher HELP/KILL/BDEMA/HASH/P2P

To add new algorithm you need to inheritance from scheduler class
and override "selector" method and add whatever you need for your 
algorithm.

---- DATA STRUCTURES ----
Each node as an LRU cache which cache the retrieved data in the past
operations. This LRU cache is implements in a way where all the 
main operations have a O(1) time complexity in the best case.

At the same time each node has two queues used as buffers among the
differents threads. The first one is used by the reciever thread and
the different.

Also the node class use a mesa monitor to synchronize the access of 
this queue.

---- ALGORITHMS ----
---- RATIONALE ----
